{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Handwritten Digit Recognition using MNIST\n",
    "\n",
    "This project aims to build a simple neural network to recognize handwritten digits using the MNIST dataset.  \n",
    "MNIST is a widely used dataset in machine learning, containing 60,000 training images and 10,000 test images of handwritten digits (0-9).  \n",
    "\n",
    "### **Objectives:**\n",
    "✅ Load and preprocess the MNIST dataset  \n",
    "✅ Build a neural network model using TensorFlow and Keras  \n",
    "✅ Train the model on handwritten digits  \n",
    "✅ Evaluate its performance on unseen test data  \n",
    "✅ Make predictions on new handwritten digits  \n"
   ],
   "id": "1e63e00b7d5610d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T04:08:31.495834Z",
     "start_time": "2025-02-13T04:06:37.624260Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading the MNIST Dataset\n",
    "\n",
    "The MNIST dataset consists of grayscale images of handwritten digits, each of size **28x28 pixels**.  \n",
    "It is preloaded in TensorFlow/Keras and can be accessed using `keras.datasets.mnist`.  \n",
    "\n",
    "### **Dataset Structure:**\n",
    "- `train_images`: A NumPy array of shape **(60000, 28, 28)** containing **60,000 training images**.\n",
    "- `train_labels`: A NumPy array of shape **(60000,)** containing labels (**digits 0-9**) for training images.\n",
    "- `test_images`: A NumPy array of shape **(10000, 28, 28)** containing **10,000 test images**.\n",
    "- `test_labels`: A NumPy array of shape **(10000,)** containing labels for the test images.\n"
   ],
   "id": "1e3ea47ea656c182"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T04:08:31.855305Z",
     "start_time": "2025-02-13T04:08:31.497895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the MNIST Dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "id": "cb3c4ff4a16e8af8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Normalization of Pixels**\n",
    "Neural networks perform better when input values are in a **small, consistent range**.  \n",
    "Since MNIST images have pixel values between **0 and 255**, we normalize them by dividing by **255.0**, scaling them to the range **[0,1]**:\n",
    "\n",
    "Example:\n",
    "- A pixel value of **0** (black) becomes **0.0**  \n",
    "- A pixel value of **128** (gray) becomes **0.502**  \n",
    "- A pixel value of **255** (white) becomes **1.0**  \n",
    "\n",
    "**Why Normalize?**\n",
    "\n",
    "✅ **Speeds up training** by making optimization more efficient  \n",
    "✅ **Prevents numerical issues** (e.g., large weight updates, exploding gradients)  \n",
    "✅ **Improves accuracy** by ensuring stable learning  \n",
    "✅ **Helps activation functions** (e.g., ReLU, Sigmoid) work effectively  "
   ],
   "id": "fe8986e7aea9aa7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T04:08:32.104023Z",
     "start_time": "2025-02-13T04:08:31.857045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize pixels for better training\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ],
   "id": "a27e4371490effa2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Building the Neural Network Model  \n",
    "\n",
    "To recognize handwritten digits, we need a neural network that can process the **28x28 pixel images** and classify them into one of **10 digits (0-9)**.  \n",
    "\n",
    "### **Model Architecture**  \n",
    "Our model is a **feedforward neural network (fully connected layers)** built using Keras' `Sequential` API:  \n",
    "\n",
    "#### Flatten Layer:\n",
    "   - Converts the **28x28 image** into a **1D array of 784 values** (since `28 × 28 = 784`).  \n",
    "   - This prepares the data for the dense (fully connected) layers.  \n",
    "\n",
    "#### Hidden Dense Layer: \n",
    "   - Contains **128 neurons** with **ReLU (Rectified Linear Unit)** activation.  \n",
    "   - ReLU introduces non-linearity, helping the model learn complex patterns.  \n",
    "\n",
    "#### Output Layer:\n",
    "   - Contains **10 neurons**, one for each digit (0-9).  \n",
    "   - Uses **Softmax activation**, which outputs probabilities for each class.  \n"
   ],
   "id": "b81dde22385d5a07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T04:08:36.550873Z",
     "start_time": "2025-02-13T04:08:32.106632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    # Add the layers\n",
    "    \n",
    "    # flatten the 28x28 image\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    \n",
    "    # hidden layer with 128 neurons\n",
    "    keras.layers.Dense(128, activation='relu'), \n",
    "    \n",
    "    # dropout to randomly turn off 20% of neurons during training\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # output layer with 10 neurons, one for each digit\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "id": "da0ec47e3396ea06",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PremieraAlpha\\College\\3rd_Year-Second Semester\\CS346 F2 Intelligent Systems 2\\Learn Artificial Intelligence\\myenv\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Compilation\n",
    "\n",
    "Before training, we need to **compile** the model, which involves configuring how it learns. Compilation defines three key components:  \n",
    "\n",
    "1. **Optimizer (`adam`)** – Determines how the model updates its weights.  \n",
    "2. **Loss Function (`sparse_categorical_crossentropy`)** – Measures the error in predictions.  \n",
    "3. **Metrics (`accuracy`)** – Evaluates model performance during training.  \n",
    "\n",
    "\n",
    "### **Why Sparse Categorical Crossentropy as the Loss Function?**  \n",
    "Since MNIST is a **multi-class classification problem** (digits 0-9), we use **cross-entropy loss**, which measures how well the predicted probabilities match the actual labels.  \n",
    "- **`sparse_categorical_crossentropy`** is used because our labels are integers (e.g., `0, 1, 2, ...`).  \n",
    "- If labels were **one-hot encoded**, we would use `categorical_crossentropy` instead."
   ],
   "id": "ea2af24ec2568e1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T04:08:36.596738Z",
     "start_time": "2025-02-13T04:08:36.559101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "ae41f145464cdcec",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train and Evaluate the Model\n",
    "\n",
    "We will train our model through 10 epochs and evaluate it accordingly."
   ],
   "id": "1971aa73fc0af2e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T04:09:57.041314Z",
     "start_time": "2025-02-13T04:08:36.598252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.fit(x_train, y_train, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Accuracy: {test_acc * 100}\")"
   ],
   "id": "323bb2ba3b0b920b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 3ms/step - accuracy: 0.8563 - loss: 0.4848\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.9554 - loss: 0.1503\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 3ms/step - accuracy: 0.9680 - loss: 0.1043\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 3ms/step - accuracy: 0.9747 - loss: 0.0841\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 3ms/step - accuracy: 0.9781 - loss: 0.0691\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 3ms/step - accuracy: 0.9799 - loss: 0.0636\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 3ms/step - accuracy: 0.9833 - loss: 0.0515\n",
      "Epoch 8/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 3ms/step - accuracy: 0.9837 - loss: 0.0508\n",
      "Epoch 9/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.9850 - loss: 0.0461\n",
      "Epoch 10/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 3ms/step - accuracy: 0.9857 - loss: 0.0421\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9766 - loss: 0.0841\n",
      "Accuracy: 98.03000092506409\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Make Predictions\n",
    "\n",
    "We will now predict the images using our model."
   ],
   "id": "875eebac7241c1e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T04:09:59.236143Z",
     "start_time": "2025-02-13T04:09:57.043154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# choose the number of image to predicted\n",
    "img_num = 10\n",
    "\n",
    "# get the image and prediction\n",
    "predictions = model.predict(x_test)\n",
    "predicted_label = np.argmax(predictions[img_num])\n",
    "\n",
    "# make a plot of the predictions\n",
    "plt.imshow(x_test[img_num], cmap=plt.cm.binary)\n",
    "plt.title(f\"Predicted: {predicted_label}\")\n",
    "plt.show()"
   ],
   "id": "73e7e1f06fc56eeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
